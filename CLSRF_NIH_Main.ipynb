{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH CXR Database Image Classifier using VGG16 and Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature Extractor: NN pretained on ImageNet\n",
    "Output layer(s): SVM - traditional machine learning classifiers\n",
    "Inspired by Sreenivas Bhattiprolu's classifier of similar approach\n",
    "https://github.com/bnsreenu/python_for_microscopists/blob/master/158_classification_CNN_RF.py\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, metrics\n",
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILITY FUCTION FOR TIME STAMPS\n",
    "import calendar, time\n",
    "from datetime import datetime\n",
    "def getTimeStamp():\n",
    "  current_GMT = time.gmtime()  # Current GMT time in a tuple format\n",
    "  ts = calendar.timegm(current_GMT)   # ts stores timestamp\n",
    "  date_time = datetime.fromtimestamp(ts)\n",
    "  return date_time.strftime(\"%m%d-%H%M%S\")  # convert timestamp to string in dd-mm-yyyy HH:MM:SS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: []  \n",
      "CPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]  \n",
      "Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:03:09) [Clang 13.0.1 ]\n",
      "Tensorflow2.9.1\n"
     ]
    }
   ],
   "source": [
    "# SHOW US WHAT YAH GOT\n",
    "import sys\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}  \")\n",
    "print(f\"CPU: {tf.config.list_physical_devices('CPU')}  \")\n",
    "print(f\"Python {sys.version}\\nTensorflow{tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "# If running on google colab, mount colab drive\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "else:\n",
    "  print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/white/Documents/AlexProjects/DICOM_OCC_MED/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORKING_DIR_TS = os.getcwd()\n",
    "WORKING_DIR_TS += '/'\n",
    "if 'google.colab' in str(get_ipython()): #if working on google colab google colab\n",
    "  WORKING_DIR_TS = '/content/drive/MyDrive/' #this is where files actually reside on google colab (that is on a mounted google drive)\n",
    "WORKING_DIR_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CONSTANSTS\n",
    "SIZE = 512  #Resize images, note original input shape for VGG is (224,244,3)\n",
    "MAX_NUMBER_OF_EACH_FINDING = 525 #Total number of image for both testing and training\n",
    "OVER_UNDER_SAMPLE_COUNT =2000\n",
    "LIMIT_SAMPLE_TO_FINDINGS = ['No Finding' ,'Infiltration','Fibrosis'] #['No Finding' ,'Infiltration','Cardiomegaly' ,'Effusion','Mass','Fibrosis']\n",
    "# MIN_AGE,MAX_AGE = 18,85\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA GENERATOR FLOW_FROM_DIRECTORY APPROACH (DEPRICATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8951 images belonging to 3 classes.\n",
      "Found 2237 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({0: 1.0, 1: 1.0, 2: 8.132716049382717},\n",
       " Counter({0: 5270, 1: 5270, 2: 648}),\n",
       " {'No Finding': 0, 'Infiltration': 1, 'Fibrosis': 2},\n",
       " 11188,\n",
       " 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SET UP DATA GENERATOR AND FLOW_FROM_DIRECTORY\n",
    "from collections import Counter\n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  validation_split=VALIDATION_SPLIT,\n",
    "  # zoom_range=0.2,\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  validation_split=VALIDATION_SPLIT,\n",
    ")\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "  'dicom/NIH_subset',\n",
    "  target_size=(SIZE, SIZE),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle = True,\n",
    "  class_mode= 'categorical', #'sparse' #',\n",
    "  classes= LIMIT_SAMPLE_TO_FINDINGS,\n",
    "  subset=\"training\"\n",
    ")\n",
    "\n",
    "val_data_generator = val_datagen.flow_from_directory(\n",
    "  'dicom/NIH_subset',\n",
    "  target_size=(SIZE, SIZE),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle = True,\n",
    "  class_mode= 'categorical', #'sparse' #',\n",
    "  classes= LIMIT_SAMPLE_TO_FINDINGS,\n",
    "  subset=\"validation\"\n",
    ")\n",
    "## SET UP CLASS WEIGHTS TO ACCOUNT FOR IMBALANCED DATASET\n",
    "counter = Counter(data_generator.classes)                          \n",
    "max_val = float(max(counter.values()))  \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}      \n",
    "\n",
    "TOTAL_SAMPLES=sum(counter.values())\n",
    "class_weights, counter,  data_generator.class_indices, TOTAL_SAMPLES, data_generator.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15387 files belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Cardiomegaly', 'Effusion', 'Fibrosis', 'Infiltration', 'Mass', 'No Finding']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds = tf.keras.utils.image_dataset_from_directory('dicom/NIH_subset',\n",
    "  label_mode='categorical' )\n",
    "tfds.class_names\n",
    "tfds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # images, labels = getImagesAndLabels(total_df)\n",
    "\n",
    "# datagen = ImageDataGenerator(rescale=1./255) #when we flow images, we want them scaled - this fuction can also be used for data augmentation\n",
    "# generator = datagen.flow_from_directory(\n",
    "#         WORKING_DIR_TS+'dicom/NIH_subset/',\n",
    "#         target_size=(SIZE, SIZE),\n",
    "#         class_mode='categorical')\n",
    "# # generator.image_shape,generator.class_indices,generator.labels[:5],generator.samples\n",
    "# generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_images, test_images, train_labels,  test_labels = train_test_split(images, labels, random_state=0, test_size = 0.2, stratify=labels)\n",
    "# train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Show the split between train and test sets.  By setting Straify = Labels it should keep the values proportional\n",
    "# unique_labels, train_labels_counts = np.unique(train_labels, return_counts=True)\n",
    "# #Show the split between train and test sets.  By setting Straify = Labels it should keep the values proportional\n",
    "# unique_labels, train_labels_counts ,np.unique(test_labels, return_counts=True), unique_labels.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels, ie from 'No Finding', 'Fibrosis', ... ====> 0, 1, ...\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(test_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "label_encoder.fit(train_labels)\n",
    "train_labels_encoded = label_encoder.transform(train_labels)\n",
    "label_encoder.classes_,train_labels[:5],train_labels_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename to standard naming conventions\n",
    "# x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESCALE AND FORMAT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Normalize pixel values to between 0 and 1\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode y values for neural network. \n",
    "# Not currently used.  Will keep in case want to used in futures.\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test)\n",
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRANSFER LEARNING  LOAD PRETRAINED KERAS APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 13:17:01.314365: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Load model without output classifier/fully connected layers, set input shape to our custom SIZE \n",
    "#This will act as a \"feature detector\"\n",
    "IMAGE_SHAPE = (SIZE, SIZE)\n",
    "print(IMAGE_SHAPE)\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False,  input_shape=(SIZE,SIZE,3), pooling='max')\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(SIZE, SIZE, 3))\n",
    "# We make sure that the base_model is running in inference mode here\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "intermediate_outputs = base_model(inputs, training=False)\n",
    "#base_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CREATE OUTPUT LAYERS AND ADD TO THE BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs categories/labels:  3\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 2048)              21802784  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 6147      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,808,931\n",
      "Trainable params: 6,147\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### CREATE A SVM (SUPPORT VECTOR MACHINE) FOR CLASSIFYING\n",
    "### SVM example: https://github.com/krishnaik06/Complete-Deep-Learning/blob/master/Image%20Classification%20Using%20SVM.ipynb\n",
    "# # #FLATTEN - MAY NOT BE NEEDED WITH SOME BASE MODELS DEPENDING OUT OUTPUT SHAPE, COULD DO GLOBALMAXPOOLING INSTEAD\n",
    "# # x = keras.layers.Flatten()(x)\n",
    "# # # Make Fully Connection Layer\n",
    "# x = keras.layers.Dense(units=16, activation='relu')(intermediate_outputs)\n",
    "# # USE LINEAR CLASSIFICATION FOR A BINARY CLASSIFIER\n",
    "# outputs = keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='linear')(x) \n",
    "# # # USE LINEAR CLASSIFICATION FOR A BINARY CLASSIFIER\n",
    "# # outputs = keras.layers.Dense(XXXXCATEGORYNUMBER, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax')(x) \n",
    "\n",
    "\n",
    "### Create a simple final dense NN layer\n",
    "outputs = tf.keras.layers.Dense( data_generator.num_classes, activation = tf.keras.activations.softmax)(intermediate_outputs)\n",
    "print(\"Model outputs categories/labels: \", data_generator.num_classes)\n",
    "\n",
    "### CREATE OUR FINAL MODEL\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# #Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "# for layer in model.layers:\n",
    "# \tlayer.trainable = False\n",
    "model.summary()  #Trainable parameters will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING THE CNN\n",
    "model.compile(\n",
    "  optimizer = 'adam', \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),#  logits=TrUe /// loss = 'hinge', \n",
    "  metrics = ['accuracy']) #'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CHECKPOINTS\n",
    "# generate path wehere you want to save your checkpoints\n",
    "checkpoint_path = f\"checkpoints/{getTimeStamp()}_weights.h5\"\n",
    "# define a callback that will save the model weights after every epoch \n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  filepath=checkpoint_path,\n",
    "  #save_weights_only=True,\n",
    "  monitor='val_accuracy',\n",
    "  mode='max',\n",
    "  verbose=1,\n",
    "  save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.6411 - accuracy: 0.3292 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.31068, saving model to checkpoints/0820-131717_weights.h5\n",
      "15/15 [==============================] - 1318s 93s/step - loss: 2.6411 - accuracy: 0.3292 - val_loss: 1.5224 - val_accuracy: 0.3107\n"
     ]
    }
   ],
   "source": [
    "#Train the CNN model, note:batch size is set in the generator\n",
    "steps_per_epoch = int(TOTAL_SAMPLES/BATCH_SIZE)\n",
    "print(steps_per_epoch);\n",
    "history = model.fit(\n",
    "  train_data_generator,\n",
    "  validation_data=val_data_generator,\n",
    "  epochs=EPOCHS, \n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  class_weight=class_weights,\n",
    "  # validation_data = (x_test, y_test), \n",
    "  callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model weights from file\n",
    "if(False): ##I don't want this to run noramlly\n",
    "  new_model = keras.models.load_model(checkpoint_path)\n",
    "    # assert_allclose(model.predict(x_train), new_model.predict(x_train), 1e-5)\n",
    "  # continue fitting the model\n",
    "  # generate a new path wehere you want to save your checkpoints\n",
    "  checkpoint_path = f\"checkpoints/{getTimeStamp()}_weights.h5\"\n",
    "  # define a callback wutg the new path name\n",
    "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "  ##RESTART TRAINING\n",
    "  history = new_model.fit( \n",
    "    x_train, y_train, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data = (x_test, y_test), \n",
    "    callbacks=[model_checkpoint_callback])\n",
    "model= keras.models.load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize training\n",
    "fig, (ax1,bx1), = plt.subplots(1, 2, sharey=True, figsize=(15, 5))\n",
    "l1, = ax1.plot(history.history['loss'], color='blue') \n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(history.history['accuracy'], color='red')\n",
    "ax1.set_ylabel('loss' , color='blue')\n",
    "ax2.set_ylabel('accuracy', color='red' )\n",
    "plt.legend([l1, l2], [\"loss\",\"accuracy\" ], loc=\"upper center\")\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Summarize Training')\n",
    "plt.figtext(0.5, 0.01, 'footnote text\\n more text \\n asdf', horizontalalignment='center', fontsize=8)\n",
    "# plt.show()\n",
    "\n",
    "# summarize validation\n",
    "# fig, ax1 = plt.subplots()\n",
    "l1, = bx1.plot(history.history['val_loss'], color='blue') \n",
    "bx2 = bx1.twinx()\n",
    "l2, = bx2.plot(history.history['val_accuracy'], color='red')\n",
    "bx1.set_ylabel('val_loss' , color='blue')\n",
    "bx2.set_ylabel('val_accuracy', color='red' )\n",
    "plt.legend([l1, l2], [\"val_loss\",\"val_accuracy\" ], loc=\"upper center\")\n",
    "plt.xlabel('epochs')\n",
    "plt.title('Summarize Validation')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/70 [..............................] - ETA: 17:40"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(val_data_generator)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/keras/engine/training.py:2033\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2032\u001b[0m   callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2033\u001b[0m   tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2034\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2035\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Transfer_Learning/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_data_generator) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXTRACT FEATURES USING THE PRETRAINED CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send test data through the model to get the output values\n",
    "X_test_feature = model.predict(x_test)\n",
    "\n",
    "# X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feature[:9],X_test_feature.shape\n",
    "flattened = X_test_feature.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A RANDOM FOREST LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_features)\n",
    "#Inverse le transform to get original label back. \n",
    "prediction_RF = label_encoder.inverse_transform(prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Print overall accuracy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(test_labels, prediction_RF)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#Print overall accuracy\n",
    "accuracy = metrics.accuracy_score(test_labels, prediction_RF)\n",
    "print (\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# from sklearn.metrics import confusion_matrix\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#Confusion Matrix - verify accuracy of each class\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cm \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mconfusion_matrix(test_labels, prediction_RF)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#print(cm)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/white/Documents/AlexProjects/DICOM_OCC_MED/CLSRF_NIH_Main.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m heatmap \u001b[39m=\u001b[39msns\u001b[39m.\u001b[39mheatmap(cm, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "cm = metrics.confusion_matrix(test_labels, prediction_RF)\n",
    "#print(cm)\n",
    "heatmap =sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Save confusion matrix\n",
    "heatmap.get_figure().savefig(f\"confusion_matrices/{getTimeStamp()}_VGG16-RF_cats{cm.shape[0]}-{MAX_NUMBER_OF_EACH_FINDING}-{NUMBER_OF_EACH_FINDING_RESERVED_FOR_TESTING}_size{SIZE}_acc{round(accuracy,2)}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check results on a few select images\n",
    "n=np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_feature=model.predict(input_img)\n",
    "input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0] \n",
    "prediction_RF = label_encoder.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction_RF)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('Transfer_Learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "342dfa87ede328b7be74dd9e2a5befe9fb3b3b15191910f7b9d300f82b7ef8a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
